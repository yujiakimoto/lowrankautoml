{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import low_rank_models as lrm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('error_matrix.csv', index_col=0)\n",
    "models = np.array(list(df))\n",
    "dataset_IDs = df.index.values\n",
    "errorMtx = df.values\n",
    "n_datasets, n_models = errorMtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \"{'hyperparameters': {'learning_rate': 3.0, 'n_estimators': 50}, 'algorithm': 'ABT'}\"\n",
      " \"{'hyperparameters': {'learning_rate': 0.0001, 'solver': 'adam', 'alpha': 0.0001}, 'algorithm': 'MLP'}\"\n",
      " \"{'hyperparameters': {'learning_rate': 1.5, 'n_estimators': 100}, 'algorithm': 'ABT'}\"\n",
      " \"{'hyperparameters': {'min_samples_split': 32, 'criterion': 'entropy'}, 'algorithm': 'RF'}\"\n",
      " \"{'hyperparameters': {'learning_rate': 2.0, 'n_estimators': 100}, 'algorithm': 'ABT'}\"\n",
      " \"{'hyperparameters': {'learning_rate': 0.01, 'solver': 'sgd', 'alpha': 0.01}, 'algorithm': 'MLP'}\"\n",
      " \"{'hyperparameters': {'min_samples_split': 1024, 'criterion': 'gini'}, 'algorithm': 'ExtraTrees'}\"\n",
      " \"{'hyperparameters': {'kernel': 'poly', 'coef0': 0, 'C': 0.125}, 'algorithm': 'kSVM'}\"]\n"
     ]
    }
   ],
   "source": [
    "n_samples = 8\n",
    "sampled_cols = lrm.pivoted_qr(errorMtx)[:n_samples]\n",
    "print(models[sampled_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = ()\n",
    "for i in range(n_datasets):\n",
    "    a = errorMtx[i].reshape(1,-1)\n",
    "    A = np.delete(errorMtx, i, axis=0)\n",
    "    a_hat = np.zeros((1, n_models))\n",
    "    a_hat[:,sampled_cols] = a[:,sampled_cols]\n",
    "    a_hat = lrm.low_rank_approximation(A, a_hat, sampled_cols)\n",
    "    predicted += (np.argsort(a_hat),)\n",
    "QR_predictions = np.vstack(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = ()\n",
    "for i in range(n_datasets):\n",
    "    a = errorMtx[i].reshape(1,-1)\n",
    "    A = np.delete(errorMtx, i, axis=0)\n",
    "    a_hat = np.zeros((1, n_models))\n",
    "    sampled_cols = np.random.permutation(n_models)[:n_samples]\n",
    "    a_hat[:,sampled_cols] = a[:,sampled_cols]\n",
    "    a_hat = lrm.low_rank_approximation(A, a_hat, sampled_cols)\n",
    "    predicted += (np.argsort(a_hat),)\n",
    "RND_predictions = np.vstack(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "breakpoints = []\n",
    "prevtype = 'kNN'\n",
    "for i in range(n_models):\n",
    "    algtype = eval(models[i])['algorithm']\n",
    "    if algtype != prevtype:\n",
    "        breakpoints.append(i)\n",
    "    prevtype = algtype\n",
    "breakpoints = [0] + breakpoints + [n_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted = ()\n",
    "for i in range(n_datasets):\n",
    "    a = errorMtx[i].reshape(1,-1)\n",
    "    A = np.delete(errorMtx, i, axis=0)\n",
    "    a_hat = np.zeros((1, n_models))\n",
    "    sampled_cols = []\n",
    "    for j in range(len(breakpoints) - 1):\n",
    "        sampled_cols.append(np.random.randint(breakpoints[j], breakpoints[j+1]))\n",
    "    sampled_cols = np.array(sampled_cols)[np.random.permutation(len(breakpoints)-1)[:n_samples]]\n",
    "    a_hat[:,sampled_cols] = a[:,sampled_cols]\n",
    "    a_hat = lrm.low_rank_approximation(A, a_hat, sampled_cols)\n",
    "    predicted += (np.argsort(a_hat),)\n",
    "SRND_predictions = np.vstack(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(QR_predictions).to_csv('predictions/rank8_QR.csv')\n",
    "pd.DataFrame(RND_predictions).to_csv('predictions/rank8_RND.csv')\n",
    "pd.DataFrame(SRND_predictions).to_csv('predictions/rank8_SRND.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k in range(30):\n",
    "    rank = k + 1\n",
    "    sampled_cols = lrm.pivoted_qr(errorMtx)[:rank]\n",
    "    predicted = ()\n",
    "    for i in range(n_datasets):\n",
    "        a = errorMtx[i].reshape(1,-1)\n",
    "        A = np.delete(errorMtx, i, axis=0)\n",
    "        a_hat = np.zeros((1, n_models))\n",
    "        a_hat[:,sampled_cols] = a[:,sampled_cols]\n",
    "        a_hat = lrm.low_rank_approximation(A, a_hat, sampled_cols)\n",
    "        predicted += (np.argsort(a_hat),)\n",
    "    QR_predictions = np.vstack(predicted)\n",
    "    pd.DataFrame(QR_predictions).to_csv('predictions/rank' + str(rank) + '_QR.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
